[{"content":"前段时间回看这几年notion和ipad里面零零散散记录的笔记，想要试图整理，却发现无论如何也无法理出可以让自己满意的条理，于是干脆全部断舍离，把它们彻底都删掉了。\n似乎从某个时间点以后就成了这个样子，对记录过去和当下的生活没有了兴趣。有时候会试图说服自己，过去都是幻影，它们本身已经没有了意义。如果遗忘了，那么正说明它们已经不重要了。然而当记忆碎片还恍惚地在脑海里浮现却没有了完整回忆的时候，心底里依然还是会对逝去的时光有一丝小小的遗憾。不在乎，也许本质上还是不够热爱自己，热爱生活，只是自己不愿承认罢了。\n来日本后，在我的notion里面有一个叫Yearly Goals的页面，每年都只有寥寥几条，但是回看发现大部分竟然也都打上了✅（19年末-来日本，20年-跳槽搬家，21年-申请永住，22年初-下签），虽然没什么实感，但生活其实也还是在有条不紊地向前走着。\n23年却停滞了，年度计划里面甚至都没有23年的页面。但是今年却也的确是最近几年里最让我“感受到了自己”的一年。所以这几天在脑海里闪过“我要写一个年末总结”的想法的同时，也产生了一丝找回了生活的实感和欣喜。\n年末总结\n话虽如此，回看这一整年却还是只能用“无趣”来形容。去掉碎片化的生活细节，今年大概只做了几件事。换个好的词来讲，做到了自己都不曾预想到的（表面）自律，甚至到了有点“走火入魔”的程度（对E人/P人来说也许是地狱式的w）\n年初时预想在上半年搞定换工作的事，于是又开始刷起了Leetcode。但是从去年底开始的layoff让整个环境变得很糟糕，四月简单投了两家没什么进展，又恰逢国内疫情隔离政策的全面解除，黄金周果断回了国，找工作的事也搁置到了下半年。于是Leetcode每日一题就这样刷着刷着，没想到真的刷齐了12个月的徽章。其实如果要正经练习DSA，这么做并没有太大的性价比，后期只是把它当成了一种玩游戏签到式的任务以及对攒徽章的执着（笑）。另一件更加无趣的事大概是墨墨，今年坚持了三个季度，第四季度终于因为没有时间而把它放弃了。 还有一件事就好玩一些了。五月开始后的两个多月一直高强度沉浸式地在海拉鲁冲浪。回看这个游戏时间，突然觉得体力下降，注意力下降等说辞大概也都只是借口。玩游戏时候的专注力可一点也不差啊（bushi）。 其它的回忆碎片：\n搬了家 看了两场live 终于开始了运动（暂时又中断了） 重新列了想要回看的经典电影list，在30代时回看和20代时真的会有完全不一样的感触 回国两趟，没有疫情又恢复了自由之身，见到了许多3年多没有见面的朋友 见了几波从国内或是其它地方过来东京玩的朋友 面了很多试 这么想来，2023年似乎也没有那么无趣。更重要的是，在2023的末尾抬头看到了更真实的世界。那种确定的，具体的，它就在那里的实感。所以也愈发期待2024年了。\n2024 - 不是展望的展望\n如果说2023年多少有点“走火入魔”，那么对2024的展望用一句话来说应该就是更接地气，更现实更“功利”地去生活吧。\n继续坚持运动，与自己的身体感受建立更直接的连接 看live，想看的赶紧去看。谁也不知道，错过了，以后还会不会再有机会 极简，但精细。不仅指物质层面，还包括时间，包括人 发展Se，感受身体（而非大脑）产生的快乐 最重要的，继续发展Si，发展有效的而非自我满足式的Si 再见，2023。\n2024，我准备好了。\n","permalink":"https://zhangwenshan001.github.io/cn/posts/annualreview/annual-review-2023/","summary":"不是总结的总结，不是展望的展望","title":"2023-2024"},{"content":"本书在11月份看了一部分，由于后来忙别的事情因此又搁置了。为了防止弃坑，先把md文件建了提交上去，push自己什么时候来填坑。\n","permalink":"https://zhangwenshan001.github.io/cn/posts/ddia/notes-for-design-data-intensive-applications/","summary":"本文为阅读《DDIA》过程中做的读书笔记","title":"《Designing Data-Intensive Applications》读书笔记"},{"content":"最近一个多月一直在断断续续阅读本书。书中会涉及到一些系统设计相关的技术内容，但个人认为该书更倾向于是一本关于面试技巧的书籍。关于具体的技术细节，如果想要深入了解，那么还是需要另外找其它材料来做补充（当然作者其实在书中也推荐了很多相关材料）。 由于之前没有中文版，自己在阅读过程中也进行了一些翻译，同时记了一些读书笔记，方便在有需要时快速回忆。（昨天看到作者本人在社交媒体上发布了中文版出版的消息，感兴趣的话也请支持正版）\n第一章 从零扩展到百万用户 简单概括系统的演进过程：\n单机（仅有web/client，CDN，以及server） 数据库服务器与应用服务器分离 添加负载均衡器（好处是故障转移，易于横向扩展等） 数据库主从复制，读写分离（提升性能，可靠性及可用性） 添加缓存 使用CDN缓存静态资源 分离会话数据，保持web层无状态（便于扩展） 引入多数据中心 使用消息队列实现异步通信 添加日志监控，指标以及自动化工具 数据库sharding 总结感想：第一章是在high-level上概括了系统演进的过程。在系统设计面试中也可以按照这个思路，从最简单的设计入手，逐步分析可能产生的问题和瓶颈，以及可以通过怎样的手段来解决。\n第二章 估值 第二章主要提到了一些对系统容量或性能进行评估时较为常见的数据，如：\n2的次方与数据量单位的对应关系，可方便速算 一些典型场景的latency，从中可以提取出一些结论来帮助设计（如memory比disk快，应尽量减少磁盘寻址，在传输数据前可尽量对其压缩等等）\n代表可用性的百分比数据\n三个九：平均每天宕机约1.44分钟，每年约8.77小时 四个九：平均每天宕机约8.64秒，每年约52.6分钟 常被问到的估计数据包括：\nDAU，QPS，峰值QPS 单条数据的大小，每天的数据量，5年的数据量 缓存，服务器数量等等 第三章 面试框架 第三章描述了一个系统设计面试的面试框架。\nstep.1 理解问题，确定设计范围\n不要一上来就开始设计，先与面试官进行沟通。对系统的功能，需求，用户量，预计增长速度和规模等等进行充分的沟通后再开始设计。\nstep.2 提出一个high-level的设计，并确认与面试官达成一致\n先不要急着讨论细节，提出初步的设计方案，并积极与面试官沟通寻求反馈。（API endpoints和DB schema是否要在这个环节进行讨论要根据实际情况来定）\nstep.3 design deep dive\n注意选择和明确具体要deep dive的topic。也要注意时间管理，有些topic并不值得花费太多时间来讨论。\nstep.4 总结\n一些follow up或自由讨论其它问题，包括但不限于：\n系统瓶颈，潜在改进点 对故障，错误等讨论 监控指标，错误日志，发布 如何处理下一个scale curve \u0026hellip; 对于45mins的面试，建议的时间分配\n第一步 3-10 mins 第二步 10-15 mins 第三步 10-25 mins 第四步 3-5 mins 第四章 设计限流器 第四章开始将会举一些具体的实例来讲解，本章介绍了限流器的设计。\n限流器的优点：\n防止Dos攻击 降低成本 减少服务器负载 \u0026hellip; 根据第三章提出的框架来推进。\n第一步：沟通，明确需求\n需要客户端还是服务端限流？ 是否是分布式系统？ 单独的限流服务还是实现在应用代码中？ 基于IP还是用户ID进行限流？ 系统规模是多大？ 若被限流，是否需要告知用户？ \u0026hellip; 第二步：提出high-level设计\n根据需求确定将功能实现在客户端or服务端，api gateway中还是添加一个middleware。 另外可明确使用的算法，常见算法有：\nToken bucket Leaking bucket Fixed window counter Sliding window log Sliding window counter 了解上述算法各自的优缺点\n第三步：design deep dive\n限流规则如何创建，如何存储 被限流后如何告知用户（可以使用一些headers） 分布式环境下存在的问题（并发更新，数据同步等） 性能优化 监控，观察分析设置的规则和算法是否有效 第四步：总结和扩展\nOSI模型应用层以外也可做限流 客户端应当怎么做来防止限流 \u0026hellip; 第五章 一致性哈希 第五章讲解了一致性哈希。\n哈希函数存在rehashing的问题。服务器数量变化时简单的模运算会导致大量的key需要重新映射，因此有了一致性哈希算法。一致性哈希算法平均只需要重新映射k/n个key\n假设使用SHA-1作为哈希函数。\n哈希环：0~2^160-1首尾相连成为哈希环。\n根据服务器IP或名称将服务器映射到哈希环上 将key也响应地映射到环上 查找过程：对于某个key，从其位置顺时针找到的第一个服务器即为该key所在服务器\n添加服务器：假设在s0和s1之间添加一个s4，则只需把s0~s4之间的key重新映射给s4\n删除服务器：同样，假设删除s1，则只需把s0~s1之间的key重新映射给s2\n存在的两个问题：\n每个服务器的分区大小不一致 key分布若不均匀，服务器映射也会不均匀 解决方法：虚拟节点。虚拟节点越多，数据分布越均匀（tradeoff：需要更多的空间来存储虚拟节点相关数据）\n总结：\n一致性哈希优点：\n服务器数量变化时重新分配的key少 数据分布均匀 缓解热点key 一致性哈希在现实中的应用实例：\nAmazon Dynamo 数据库的分区组件 Apache Cassandra 中跨集群的数据分区 Discord 聊天应用程序 Akamai 内容交付网络 Maglev 网络负载均衡器 第六章 设计一个k-v存储 features如下：\n单个k-v小于10k 支持大量数据 高可用 高可扩展 自动扩展 可调节的一致性 低延迟 CAP理论\nCP/AP/CA系统分别的特征 分布式系统必须保证P CP/AP有代表性的系统举例 数据分区（存储大量数据的能力、增量扩容）：采用第五章中提到的一致性哈希\n数据复制（高可用读）：同样利用哈希环，在环上的多个节点复制数据\n可调节的一致性（tunable consistency）：quorum consensus方式去保证读和写操作的一致性。（调整N W R数值）\nW+R\u0026gt;N：保证强一致性 R=1 W=N：快速读 W=1 R=N：快速写 一致性模型：关于强一致性和弱一致性（最终一致性）\n解决不一致问题（高可用写）：版本控制\u0026amp;向量时钟(vector clock)\n故障检测：gossip协议\n处理临时故障： sloppy quorum/hinted handoff\n处理永久性故障：merkle tree\n（本章有点理论和抽象，需要再巩固）\n第七章 设计一个唯一ID生成器 第一步，提问明确需求\n本例中需求：\nid唯一 id只含数字 长度64bit 可通过日期排序 每秒支持生成10000个id 第二步 high-level设计\n考虑四种方法：\nMulti-master replication(db auto increment by k) UUID (128bit 优点各服务器可单独负责生成id) Ticket Server(单独db专门负责id自增，缺点是单点故障) Twitter snowflake approach（符号位0+41位timestamp+5位datacenterID+5位machineID+12位序列号） 第三步 deep dive\nTwitter snowflake approach满足需求 41位timestamp够用69年 12位序列号，每台机器每毫秒可支持4096个新id 第四步 总结\n其它讨论：\n时钟同步 各个section的长度可根据需求适当调整 高可用 第八章 设计url短网址 第一步：明确需求\n可通过long url生成short url 可通过short url重定向回long url 支持每天1亿（100million）url short url尽可能短 short url支持0-9/a-z/A-Z short url无需更新或删除 高可用，可扩展，容错 Back of the envelope estimation\n写操作：1million/24/3600 = 1160/s 读操作：假设为写操作的10倍： 11600/s 假设存储10年的数据：100million * 365 * 10 = 365 billion 假设平均长度100bytes，则总存储 365billion * 100 bytes = 36T（书里好像算错了） 第二步 high-level设计\nAPI endpoints\nPOST /api/v1/data/shorten # 请求body {longUrl: longUrl} # 返回 short url GET /api/v1/shortUrl # 返回 longUrl URL重定向：301（永久，负载小） vs 302（临时，便于收集和分析数据）\n第三步：deep dive\n数据模型\nSQL：{id, longUrl, shortUrl} （补充：NoSQL，需要分别存储两张表）\n哈希\nlength≥6 → 56.8 billion length≥7 → 3.6 trillion 两种方式：\nHash + 冲突解决 Base62 URL重定向：读多写少，加LB，加缓存\n第四步 总结\n可讨论的点：\n限流 web服务器扩展（stateless扩展容易） db扩展 数据收集分析 可用性, 一致性, 可靠性 第九章 设计网络爬虫 爬虫的原理：首先收集一些种子页面，然后跟踪这些页面的链接来收集新的链接，如此循环。\n爬虫用途：\n搜索引擎索引（如googlebot） 网络档案（如图书馆档案） 网络挖掘（如金融公司爬虫获取股东会议和年度报告等） 网络监控（版权，商标侵权，盗版发现） 第一步 提问明确需求\n本例中需求：\n用于搜索引擎索引 每月1billion的页面 只考虑HTML 需考虑网页新增和更新 HTML最长存储5年 需要忽略重复内容 可以考虑的特性：\n可扩展性（Scalability：易于扩展规模） 稳健性（处理特殊case） 礼貌性（不能短时间向同一网站发送太多请求） 可扩展性（Extensibility：易于增加新功能） 估值：\n假设每月下载1billion页面 QPS：400/s Peak QPS: 400*2 = 800/2 假设每个页面大小500k 1billion * 500k = 500T每月 5年存储：500T * 12 * 5 = 30PB 第二步 high-level设计 第三步 深入讨论\n算法：DFS vs BFS DFS深度太深，一般不适用于爬虫。 使用BFS考虑以下两个问题： 大量请求同时爬同一个网站，不友好 需要考虑不同网站优先级 URL frontier 添加两组队列： 优先级管理：对URL进行优先级排序，并放入不同优先级的队列中 Politeness管理：将特定host映射到同一个队列，并在worker维持一个delay 保持内容最新：全部重新爬虫费时费资源，可考虑一些策略来更新部分网站内容 存储：磁盘和内容混合存储，添加缓冲区等 HTML下载器 Robots Exclusion Protocol 性能优化 分布式 缓存DNS解析结果 考虑地理位置优化 设置超时时间 保持稳健性 通过一致性哈希扩展下载服务器 保存爬虫状态和数据，可在故障后重启 异常处理 数据验证 功能扩展 增加图片下载 增加监控模块 \u0026hellip; 问题内容检测 校验冗余 Spider traps检验 噪音排除 第四步 总结\n其它可讨论的点：\n为支持动态生成的链接，在解析页面前可进行服务端渲染 垃圾过滤 水平扩展 可用性、一致性和可靠性 添加分析器 第十章 设计通知系统 本章将会设计一个通知系统。 通知不仅仅包含推送通知，通知的三种形式为：\n推送通知 SMS通知 邮件通知 第一步 理解问题，确定设计范围\n本例的设计需求：\n支持上述三种通知 软实时，用户尽快收到通知。但高负载下可接受轻微延迟 支持设备：ios，android，laptop，pc 客户端和服务端均可触发通知 用户可自主设置是否关闭通知 通知的数量：每天10million推送，1million SMS消息，5million邮件 第二步 high-level设计\n不同通知类型需要的组件 iOS provider提供以下数据 device token payload APNs device Android 与上述类似，替换FCM SMS消息 第三方的SMS服务例如Twilio，Nexmo Email Sendgrid，Mailchimp等商业服务 联系方式收集工作流 用户安装或首次登录时记录数据到DB 用户与设备可能是一对多 通知发送/接收工作流 Service 1 to N 通知系统 第三方服务 客户端设备 存在的一些改进点\nSPOF 单个通知服务器难以扩展 性能瓶颈 改进\n将数据库、缓存移出通知服务器 增加通知服务器，水平扩展 引入消息队列，解耦 改进后的工作流：\nService 1 to N 通知系统 缓存 DB MQ workers 第三方服务 客户端设备 第三步 design deep dive\n可靠性 如何防止数据丢失：持久化 接收者是否会准确地收到一次通知：分布式的特性会导致重复，引入去重复机制减少重复发生率 额外的组件以及考虑点 通知模板 通知设置 限流 重试机制 安全性 监控队列通知 事件追踪 第四步 总结\n整理并回顾下上述的内容。\n第十一章 设计news feed 第一步 提问，理解问题\n第二步 high-level设计\n关键设计为两块：feed发布和feed获取（可把endpoint和参数也设计一下）\nfeed发布：可包含post service \u0026amp; fanout service \u0026amp; 对应db\u0026amp;cache feed获取：news feed service \u0026amp; 对应cache 第三步 深入讨论\nfanout的两种方式讨论，具体存储的数据结构是怎样的，pros\u0026amp;cons分别是什么（可以结合两种方式对不同场景进行优化）\n媒体文件的存储，CDN （补充，可以讨论file storage的优点）\n缓存（feed缓存，热门content缓存，社交关系，用户行为缓存，计数器）\n第四步 总结\n其它可讨论的点：\n垂直/水平扩展 SQL\u0026amp;NoSQL 主从复制\u0026amp;replica sharding\u0026amp;一致性模型 stateless 多数据中心 MQ 监控Metrics 补充：本题做mock时存在的问题\n对db和cache的选择讨论较少，可有针对性加强 尽量不要长时间沉默思考，speak out loudly or ask questions ","permalink":"https://zhangwenshan001.github.io/cn/posts/systemdesign/notes-for-system-design-interview-an-insiders-guide/","summary":"本文为阅读Alex Xu的《系统设计面试》一书过程中做的读书笔记的总结","title":"《系统设计面试》读书笔记"},{"content":"一直以来都有搭建一个私人blog的想法，奈何迟迟没有行动。趁着最近一些变化以及行动力还未消退，周末尝试着直接利用github部署了一个简单的blog。本文将会对整个过程进行简单地记录。\ngithub仓库 首先，我们需要有一个github账号。还没有的话先注册一个。 新建repository，格式是 [username].github.io 如果想使用github默认支持的Github Pages，则可通过 project \u0026gt; Settings \u0026gt; Github Pages \u0026gt; Choose a theme 直接选择一个Jekyll主题，简单地编辑一下index.md的内容，然后commit changes，网站主页就大功告成了。 静态页面生成器 除了Jekyll，还有许多静态页面生成器，这里简单地对以下三个静态页生成器极其特点进行了比较总结。\nHugo: Go语言开发 生成静态页面速度非常快 github stared 70k Jekyll Ruby语言开发 Github Pages默认支持的 github stared 47k Hexo Node.js开发 中文社区支持较好 github stared 37k 老实说具体的差别目前还没有深入研究，作为后端工程师总之就先选hugo吧，以后碰到问题再仔细了解。\nHugo \u0026amp; PaperMod 快速开始 根据步骤首先安装Hugo brew install hugo 用hugo创建一个新项目 hugo new site \u0026lt;name of site\u0026gt; --format yaml cd \u0026lt;name of site\u0026gt; 找一个简单好看的主题，本次采用PaperMod （也可以通过submodule的方式添加） git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 更新时\ncd themes/PaperMod git pull 修改配置文件config.yml中的主题 theme: \u0026#34;PaperMod\u0026#34; PaperMod的页面配置需要自己简单学习下各个配置项。为了方便起见，本次我就直接把它的demo下载下来修改了一下，总之先把项目跑起来。\n添加文章 用以下命令生成一个md文件并进行编辑（也就是现在正在编辑的这篇文章）\nhugo new content [PATH_TO_NEW_POST].md 没有写过markdown文档的话，也需要简单熟悉一下，这里就不赘述了，自行谷歌一下。\n本地预览 使用以下命令启动本地环境，默认可以在http://localhost:1313/进行访问\nhugo server 如果想要确认草稿，也可以带上参数启动本地服务\nhugo server --buildDrafts hugo server -D 发布 以下命令将会发布静态页面\nhugo 部署 内容确认完毕后，将整个项目提交到 [username].github.io仓库。 接下来的一个问题是部署。直接在Github Pages里选择main分支部署是不行的。还需要添加一个github的workflow。 参考这个项目：actions-hugo。\n添加以下内容到 .github/workflows/gh-pages.yml\nname: github pages on: push: branches: - main # Set a branch to deploy jobs: deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;0.121.1\u0026#34; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 添加上述文件后，当代码提交到main分支时github actions会自动执行，并将生成的静态页面提交到gh-pages分支，这里需要注意下，默认情况下Workflow permissions可能没有修改和创建分支的权限，需要在 project \u0026gt; Settings \u0026gt; Actions \u0026gt; General \u0026gt; Workflow permissions 里设置一下权限。\n最后在Github Pages的配置中选择gh-pages分支进行部署，整个过程就完成了。\nLicense Copyright 2023-present Wenshan.\n","permalink":"https://zhangwenshan001.github.io/cn/posts/papermod/build-my-blog-by-hugo/","summary":"本文记录了该blog构建的过程，主要采用Hugo+PaperMod主题+github部署","title":"使用Hugo构建个人blog"}]