[{"content":"最近一个多月一直在断断续续阅读本书。书中会涉及到一些系统设计相关的技术内容，但个人认为该书更倾向于是一本关于面试技巧的书籍。关于具体的技术细节，如果想要深入了解，那么还是需要另外找其它材料来做补充（当然作者其实在书中也推荐了很多相关材料）。 由于之前没有中文版，自己在阅读过程中也进行了一些翻译，同时记了一些读书笔记，方便在有需要时快速回忆。（昨天看到作者本人在社交媒体上发布了中文版出版的消息，感兴趣的话也请支持正版w）\n第一章 从零扩展到百万用户 简单概括系统的演进过程：\n单机（仅有web/client，CDN，以及server） 数据库服务器与应用服务器分离 添加负载均衡器（好处是故障转移，易于横向扩展等） 数据库主从复制，读写分离（提升性能，可靠性及可用性） 添加缓存 使用CDN缓存静态资源 分离会话数据，保持web层无状态（便于扩展） 引入多数据中心 使用消息队列实现异步通信 添加日志监控，指标以及自动化工具 数据库sharding 总结感想：第一章是在high-level上概括了系统演进的过程。在系统设计面试中也可以按照这个思路，从最简单的设计入手，逐步分析可能产生的问题和瓶颈，以及可以通过怎样的手段来解决。\n第二章 估值 （back-of-the-envelope estimation不知道该怎么准确翻译）\n第二章主要提到了一些对系统容量或性能进行评估时较为常见的数据，如：\n2的次方与数据量单位的对应关系，可方便速算 一些典型场景的latency，从中可以提取出一些结论来帮助设计（如memory比disk快，应尽量减少磁盘寻址，在传输数据前可尽量对其压缩等等）\n代表可用性的百分比数据\n三个九：平均每天宕机约1.44分钟，每年约8.77小时 四个九：平均每天宕机约8.64秒，每年约52.6分钟 常被问到的估计数据包括：\nDAU，QPS，峰值QPS 单条数据的大小，每天的数据量，5年的数据量 缓存，服务器数量等等 第三章 面试框架 第三章描述了一个系统设计面试的面试框架。\nstep.1 理解问题，确定设计范围\n不要一上来就开始设计，先与面试官进行沟通。对系统的功能，需求，用户量，预计增长速度和规模等等进行充分的沟通后再开始设计。\nstep.2 提出一个high-level的设计，并确认与面试官达成一致\n先不要急着讨论细节，提出初步的设计方案，并积极与面试官沟通寻求反馈。（API endpoints和DB schema是否要在这个环节进行讨论要根据实际情况来定）\nstep.3 design deep dive\n注意选择和明确具体要deep dive的topic。也要注意时间管理，有些topic并不值得花费太多时间来讨论。\nstep.4 总结\n一些follow up或自由讨论其它问题，包括但不限于：\n系统瓶颈，潜在改进点 对故障，错误等讨论 监控指标，错误日志，发布 如何处理下一个scale curve \u0026hellip; 对于45mins的面试，建议的时间分配\n第一步 3-10 mins 第二步 10-15 mins 第三步 10-25 mins 第四步 3-5 mins 第四章 设计限流器 第四章开始将会举一些具体的实例来讲解，本章介绍了限流器的设计。\n限流器的优点：\n防止Dos攻击 降低成本 减少服务器负载 \u0026hellip; 根据第三章提出的框架来推进。\n第一步：沟通，明确需求\n需要客户端还是服务端限流？ 是否是分布式系统？ 单独的限流服务还是实现在应用代码中？ 基于IP还是用户ID进行限流？ 系统规模是多大？ 若被限流，是否需要告知用户？ \u0026hellip; 第二步：提出high-level设计\n根据需求确定将功能实现在客户端or服务端，api gateway中还是添加一个middleware。 另外可明确使用的算法，常见算法有：\nToken bucket Leaking bucket Fixed window counter Sliding window log Sliding window counter 了解上述算法各自的优缺点\n第三步：design deep dive\n限流规则如何创建，如何存储 被限流后如何告知用户（可以使用一些headers） 分布式环境下存在的问题（并发更新，数据同步等） 性能优化 监控，观察分析设置的规则和算法是否有效 第四步：总结和扩展\nOSI模型应用层以外也可做限流 客户端应当怎么做来防止限流 \u0026hellip; 第五章 一致性哈希 第五章讲解了一致性哈希。\n哈希函数存在rehashing的问题。服务器数量变化时简单的模运算会导致大量的key需要重新映射，因此有了一致性哈希算法。一致性哈希算法平均只需要重新映射k/n个key\n假设使用SHA-1作为哈希函数。\n哈希环：0~2^160-1首尾相连成为哈希环。\n根据服务器IP或名称将服务器映射到哈希环上 将key也响应地映射到环上 查找过程：对于某个key，从其位置顺时针找到的第一个服务器即为该key所在服务器\n添加服务器：假设在s0和s1之间添加一个s4，则只需把s0~s4之间的key重新映射给s4\n删除服务器：同样，假设删除s1，则只需把s0~s1之间的key重新映射给s2\n存在的两个问题：\n每个服务器的分区大小不一致 key分布若不均匀，服务器映射也会不均匀 解决方法：虚拟节点。虚拟节点越多，数据分布越均匀（tradeoff：需要更多的空间来存储虚拟节点相关数据）\n总结：\n一致性哈希优点：\n服务器数量变化时重新分配的key少 数据分布均匀 缓解热点key 一致性哈希在现实中的应用实例：\nAmazon Dynamo 数据库的分区组件 Apache Cassandra 中跨集群的数据分区 Discord 聊天应用程序 Akamai 内容交付网络 Maglev 网络负载均衡器 第六章 设计一个k-v存储 features如下：\n单个k-v小于10k 支持大量数据 高可用 高可扩展 自动扩展 可调节的一致性 低延迟 CAP理论\nCP/AP/CA系统分别的特征 分布式系统必须保证P CP/AP有代表性的系统举例 数据分区（存储大量数据的能力、增量扩容）：采用第五章中提到的一致性哈希\n数据复制（高可用读）：同样利用哈希环，在环上的多个节点复制数据\n可调节的一致性（tunable consistency）：quorum consensus方式去保证读和写操作的一致性。（调整N W R数值）\nW+R\u0026gt;N：保证强一致性 R=1 W=N：快速读 W=1 R=N：快速写 一致性模型：关于强一致性和弱一致性（最终一致性）\n解决不一致问题（高可用写）：版本控制\u0026amp;向量时钟(vector clock)\n故障检测：gossip协议\n处理临时故障： sloppy quorum/hinted handoff\n处理永久性故障：merkle tree\n（本章有点理论和抽象，需要再巩固）\n第七章 设计一个唯一ID生成器 第一步，提问明确需求 本例中需求：\nid唯一 id只含数字 长度64bit 可通过日期排序 每秒支持生成10000个id 第二步 high-level设计\n考虑四种方法：\nMulti-master replication(db auto increment by k) UUID (128bit 优点各服务器可单独负责生成id) Ticket Server(单独db专门负责id自增，缺点是单点故障) Twitter snowflake approach（符号位0+41位timestamp+5位datacenterID+5位machineID+12位序列号） 第三步 deep dive\nTwitter snowflake approach满足需求 41位timestamp够用69年 12位序列号，每台机器每毫秒可支持4096个新id 第四步 总结\n其它讨论：\n时钟同步 各个section的长度可根据需求适当调整 高可用 第八章 设计url短网址 第一步：明确需求\n可通过long url生成short url 可通过short url重定向回long url 支持每天1亿（100million）url short url尽可能短 short url支持0-9/a-z/A-Z short url无需更新或删除 高可用，可扩展，容错 Back of the envelope estimation\n写操作：1million/24/3600 = 1160/s 读操作：假设为写操作的10倍： 11600/s 假设存储10年的数据：100million * 365 * 10 = 365 billion 假设平均长度100bytes，则总存储 365billion * 100 bytes = 36T（书里好像算错了） 第二步 high-level设计\nAPI endpoints\nPOST /api/v1/data/shorten # 请求body {longUrl: longUrl} # 返回 short url GET /api/v1/shortUrl # 返回 longUrl URL重定向：301（永久，负载小） vs 302（临时，便于收集和分析数据）\n第三步：deep dive\n数据模型\nSQL：{id, longUrl, shortUrl} （补充：NoSQL，需要分别存储两张表）\n哈希\nlength≥6 → 56.8 billion length≥7 → 3.6 trillion 两种方式：\nHash + 冲突解决 Base62 URL重定向：读多写少，加LB，加缓存\n第四步 总结\n可讨论的点：\n限流 web服务器扩展（stateless扩展容易） db扩展 数据收集分析 可用性, 一致性, 可靠性 第十一章 设计news feed 第一步 提问，理解问题\n第二步 high-level设计\n关键设计为两块：feed发布和feed获取（可把endpoint和参数也设计一下）\nfeed发布：可包含post service \u0026amp; fanout service \u0026amp; 对应db\u0026amp;cache feed获取：news feed service \u0026amp; 对应cache 第三步 深入讨论\nfanout的两种方式讨论，具体存储的数据结构是怎样的，pros\u0026amp;cons分别是什么（可以结合两种方式对不同场景进行优化）\n媒体文件的存储，CDN （补充，可以讨论file storage的优点）\n缓存（feed缓存，热门content缓存，社交关系，用户行为缓存，计数器）\n第四步 总结\n其它可讨论的点：\n垂直/水平扩展 SQL\u0026amp;NoSQL 主从复制\u0026amp;replica sharding\u0026amp;一致性模型 stateless 多数据中心 MQ 监控Metrics 补充：本题做mock时存在的问题\n对db和cache的选择讨论较少，可有针对性加强 尽量不要长时间沉默思考，speak out loudly or ask questions ","permalink":"https://zhangwenshan001.github.io/cn/posts/systemdesign/notes-for-system-design-interview-an-insiders-guide/","summary":"本文为阅读Alex Xu的《系统设计面试》一书过程中做的读书笔记的总结","title":"《系统设计面试》读书笔记"},{"content":"一直以来都有搭建一个私人blog的想法，奈何迟迟没有行动。趁着最近一些变化以及行动力还未消退，周末尝试着直接利用github部署了一个简单的blog。本文将会对整个过程进行简单地记录。\ngithub仓库 首先，我们需要有一个github账号。还没有的话先注册一个。 新建repository，格式是 [username].github.io 如果想使用github默认支持的Github Pages，则可通过 project \u0026gt; Settings \u0026gt; Github Pages \u0026gt; Choose a theme 直接选择一个Jekyll主题，简单地编辑一下index.md的内容，然后commit changes，网站主页就大功告成了。 静态页面生成器 除了Jekyll，还有许多静态页面生成器，这里简单地对以下三个静态页生成器极其特点进行了比较总结。\nHugo: Go语言开发 生成静态页面速度非常快 github stared 70k Jekyll Ruby语言开发 Github Pages默认支持的 github stared 47k Hexo Node.js开发 中文社区支持较好 github stared 37k 老实说具体的差别目前还没有深入研究，作为后端工程师总之就先选hugo吧，以后碰到问题再仔细了解。\nHugo \u0026amp; PaperMod 快速开始 根据步骤首先安装Hugo brew install hugo 用hugo创建一个新项目 hugo new site \u0026lt;name of site\u0026gt; --format yaml cd \u0026lt;name of site\u0026gt; 找一个简单好看的主题，本次采用PaperMod （也可以通过submodule的方式添加） git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 更新时\ncd themes/PaperMod git pull 修改配置文件config.yml中的主题 theme: \u0026#34;PaperMod\u0026#34; PaperMod的页面配置需要自己简单学习下各个配置项。为了方便起见，本次我就直接把它的demo下载下来修改了一下，总之先把项目跑起来。\n添加文章 用以下命令生成一个md文件并进行编辑（也就是现在正在编辑的这篇文章）\nhugo new content [PATH_TO_NEW_POST].md 没有写过markdown文档的话，也需要简单熟悉一下，这里就不赘述了，自行谷歌一下。\n本地预览 使用以下命令启动本地环境，默认可以在http://localhost:1313/进行访问\nhugo server 如果想要确认草稿，也可以带上参数启动本地服务\nhugo server --buildDrafts hugo server -D 发布 以下命令将会发布静态页面\nhugo 部署 内容确认完毕后，将整个项目提交到 [username].github.io仓库。 接下来的一个问题是部署。直接在Github Pages里选择main分支部署是不行的。还需要添加一个github的workflow。 参考这个项目：actions-hugo。\n添加以下内容到 .github/workflows/gh-pages.yml\nname: github pages on: push: branches: - main # Set a branch to deploy jobs: deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;0.121.1\u0026#34; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 添加上述文件后，当代码提交到main分支时github actions会自动执行，并将生成的静态页面提交到gh-pages分支，这里需要注意下，默认情况下Workflow permissions可能没有修改和创建分支的权限，需要在 project \u0026gt; Settings \u0026gt; Actions \u0026gt; General \u0026gt; Workflow permissions 里设置一下权限。\n最后在Github Pages的配置中选择gh-pages分支进行部署，整个过程就完成了。\nLicense Copyright 2023-present Wenshan.\n","permalink":"https://zhangwenshan001.github.io/cn/posts/papermod/build-my-blog-by-hugo/","summary":"本文记录了该blog构建的过程，主要采用Hugo+PaperMod主题+github部署","title":"使用Hugo构建个人blog"}]